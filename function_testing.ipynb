{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8753a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 72.1M/72.1M [00:04<00:00, 16.2MiB/s]\n",
      "C:\\Users\\vitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test test test I'm gonna be talking like this let's see how it handles when it's super loud and then also when I'm really close and it's super loud or when I'm pretty far away and it's kind of quiet let's see if it can handle a little bit of this a little bit of that some flaps and I think birthday party power off run function meeting at 5 p.m. in new Plaza Square you need a doctor's appointment pretty soon make sure you get that going don't forget to visit the birthday party at 7 p.m.\n"
     ]
    }
   ],
   "source": [
    "#first it decodes the message and writes it as a text file:\n",
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"tiny\")  # Options: tiny, base, small, medium, large\n",
    "\n",
    "result = model.transcribe(\"command_test.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661e7e9",
   "metadata": {},
   "source": [
    "first lets see if it can do this in real time. \n",
    "to do this, since the model is trained on 30 second intervals we will need to break the audio up into 30 second chunks.\n",
    "then while its transcribing one section, it will be recording the next section, that way its going to be at most 30 seconds behind.\n",
    "it will save these 30 second chunks to a file, labeled with date and time and then it will search through the file for any new information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorder: Recording audio...\n",
      "Main: Running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Exception in thread Thread-4 (processing_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1520.0_x64__qbz5n2kfra8p0\\Lib\\threading.py\"\u001b[0m, line \u001b[35m1043\u001b[0m, in \u001b[35m_bootstrap_inner\u001b[0m\n",
      "    \u001b[31mself.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\vitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ipykernel\\ipkernel.py\"\u001b[0m, line \u001b[35m766\u001b[0m, in \u001b[35mrun_closure\u001b[0m\n",
      "    \u001b[31m_threading_Thread_run\u001b[0m\u001b[1;31m(self)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1520.0_x64__qbz5n2kfra8p0\\Lib\\threading.py\"\u001b[0m, line \u001b[35m994\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mself._target\u001b[0m\u001b[1;31m(*self._args, **self._kwargs)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\vitya\\AppData\\Local\\Temp\\ipykernel_46116\\3650845021.py\"\u001b[0m, line \u001b[35m68\u001b[0m, in \u001b[35mprocessing_thread\u001b[0m\n",
      "    \u001b[31mtranscribe_audio\u001b[0m\u001b[1;31m(audio_data)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\vitya\\AppData\\Local\\Temp\\ipykernel_46116\\3650845021.py\"\u001b[0m, line \u001b[35m55\u001b[0m, in \u001b[35mtranscribe_audio\u001b[0m\n",
      "    result = model.transcribe(buffer_mp3)\n",
      "  File \u001b[35m\"C:\\Users\\vitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\whisper\\transcribe.py\"\u001b[0m, line \u001b[35m139\u001b[0m, in \u001b[35mtranscribe\u001b[0m\n",
      "    mel = log_mel_spectrogram(audio, model.dims.n_mels, padding=N_SAMPLES)\n",
      "  File \u001b[35m\"C:\\Users\\vitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\whisper\\audio.py\"\u001b[0m, line \u001b[35m141\u001b[0m, in \u001b[35mlog_mel_spectrogram\u001b[0m\n",
      "    audio = torch.from_numpy(audio)\n",
      "\u001b[1;35mTypeError\u001b[0m: \u001b[35mexpected np.ndarray (got _io.BytesIO)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorder: Finished recording.\n",
      "Recorder: Audio added to queue.\n",
      "Recorder: Recording audio...\n",
      "Transcriber: Transcribing audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Audio added to queue.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Audio added to queue.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Audio added to queue.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Audio added to queue.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Audio added to queue.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Queue is full, skipping this recording.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Queue is full, skipping this recording.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Queue is full, skipping this recording.\n",
      "Recorder: Recording audio...\n",
      "Main: Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import os\n",
    "import numpy as np\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "from pydub import AudioSegment\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "file_lock = threading.Lock()\n",
    "\n",
    "duration = 30  # seconds\n",
    "samplerate = 16000\n",
    "stop_recording = False\n",
    "\n",
    "recording_buffer = {\n",
    "    \"Thread-1\": None,\n",
    "    \"Thread-2\": None\n",
    "}\n",
    "\n",
    "def record_audio(thread_name):\n",
    "    print(f\"{thread_name}: Recording for {duration}s...\")\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    return recording\n",
    "\n",
    "def save_and_transcribe(thread_name, audio_data):\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S-%f\")\n",
    "    wav_filename = f\"{thread_name}_{current_datetime}.wav\"\n",
    "    mp3_filename = f\"{thread_name}_{current_datetime}.mp3\"\n",
    "\n",
    "    write(wav_filename, samplerate, audio_data)\n",
    "    audio = AudioSegment.from_wav(wav_filename)\n",
    "    audio.export(mp3_filename, format=\"mp3\")\n",
    "    os.remove(wav_filename)\n",
    "\n",
    "    print(f\"{thread_name}: Transcribing...\")\n",
    "    result = model.transcribe(mp3_filename)\n",
    "    clean_text = result[\"text\"].replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "\n",
    "    with file_lock:\n",
    "        with open(\"transcription.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"[{datetime.now()}][{thread_name}] {clean_text}\\n\")\n",
    "\n",
    "    os.remove(mp3_filename)\n",
    "    print(f\"{thread_name}: Transcription complete and file cleaned up.\")\n",
    "\n",
    "def worker(my_name, partner_name):\n",
    "    global stop_recording\n",
    "    while not stop_recording:\n",
    "        # Record audio\n",
    "        audio_data = record_audio(my_name)\n",
    "        # Store for the partner to process later (if needed)\n",
    "        recording_buffer[my_name] = audio_data\n",
    "\n",
    "        # Allow partner to record while this thread processes previous data\n",
    "        if recording_buffer[partner_name] is not None:\n",
    "            save_and_transcribe(partner_name, recording_buffer[partner_name])\n",
    "            recording_buffer[partner_name] = None\n",
    "        else:\n",
    "            # If partner hasn't recorded yet, process own data\n",
    "            save_and_transcribe(my_name, audio_data)\n",
    "            recording_buffer[my_name] = None\n",
    "\n",
    "def start_alternating_threads():\n",
    "    thread1 = threading.Thread(target=worker, args=(\"Thread-1\", \"Thread-2\"))\n",
    "    thread2 = threading.Thread(target=worker, args=(\"Thread-2\", \"Thread-1\"))\n",
    "\n",
    "    thread1.start()\n",
    "    # Stagger the second thread to alternate\n",
    "    time.sleep(duration)\n",
    "    thread2.start()\n",
    "\n",
    "    return thread1, thread2\n",
    "\n",
    "try:\n",
    "    thread1, thread2 = start_alternating_threads()\n",
    "    runtime = 5 * 60  # Run for 5 minutes, adjust as needed\n",
    "    time.sleep(runtime)\n",
    "    stop_recording = True\n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    print(\"Recording and transcription stopped.\")\n",
    "except KeyboardInterrupt:\n",
    "    stop_recording = True\n",
    "    print(\"Stopped by user.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5484b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code words and new information\n",
    "# first it will look throught the transcript for any new information.\n",
    "# it will do this any time that there is a break in the transcription.\n",
    "# every 5 minutes it will check through the transcript to see if there is a break with no new text\n",
    "# if there isnt, then it will look through from the last time it checked, up to the current time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2983c779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import os\n",
    "import numpy as np\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "from pydub import AudioSegment\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "file_lock = threading.Lock()\n",
    "\n",
    "duration = 30  # seconds\n",
    "samplerate = 16000\n",
    "stop_recording = False\n",
    "\n",
    "recording_buffer = {\n",
    "    \"Thread-1\": None,\n",
    "    \"Thread-2\": None\n",
    "}\n",
    "\n",
    "def record_audio(thread_name):\n",
    "    print(f\"{thread_name}: Recording for {duration}s...\")\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    return recording\n",
    "\n",
    "def save_and_transcribe(thread_name, audio_data):\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S-%f\")\n",
    "    wav_filename = f\"{thread_name}_{current_datetime}.wav\"\n",
    "    mp3_filename = f\"{thread_name}_{current_datetime}.mp3\"\n",
    "\n",
    "    write(wav_filename, samplerate, audio_data)\n",
    "    audio = AudioSegment.from_wav(wav_filename)\n",
    "    audio.export(mp3_filename, format=\"mp3\")\n",
    "    os.remove(wav_filename)\n",
    "\n",
    "    print(f\"{thread_name}: Transcribing...\")\n",
    "    result = model.transcribe(mp3_filename)\n",
    "    clean_text = result[\"text\"].replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "\n",
    "    with file_lock:\n",
    "        with open(\"transcription.txt\", \"a\") as f:\n",
    "            f.write(f\"[{datetime.now()}][{thread_name}] {clean_text}\\n\")\n",
    "\n",
    "    os.remove(mp3_filename)\n",
    "    print(f\"{thread_name}: Transcription complete and file cleaned up.\")\n",
    "\n",
    "def worker(my_name, partner_name):\n",
    "    global stop_recording\n",
    "    while not stop_recording:\n",
    "        # Record audio\n",
    "        audio_data = record_audio(my_name)\n",
    "        # Store for the partner to process later (if needed)\n",
    "        recording_buffer[my_name] = audio_data\n",
    "\n",
    "        # Allow partner to record while this thread processes previous data\n",
    "        if recording_buffer[partner_name] is not None:\n",
    "            save_and_transcribe(partner_name, recording_buffer[partner_name])\n",
    "            recording_buffer[partner_name] = None\n",
    "        else:\n",
    "            # If partner hasn't recorded yet, process own data\n",
    "            save_and_transcribe(my_name, audio_data)\n",
    "            recording_buffer[my_name] = None\n",
    "\n",
    "def start_alternating_threads():\n",
    "    thread1 = threading.Thread(target=worker, args=(\"Thread-1\", \"Thread-2\"))\n",
    "    thread2 = threading.Thread(target=worker, args=(\"Thread-2\", \"Thread-1\"))\n",
    "\n",
    "    thread1.start()\n",
    "    # Stagger the second thread to alternate\n",
    "    time.sleep(duration)\n",
    "    thread2.start()\n",
    "\n",
    "    return thread1, thread2\n",
    "\n",
    "try:\n",
    "    thread1, thread2 = start_alternating_threads()\n",
    "    runtime = 5 * 60  # Run for 5 minutes, adjust as needed\n",
    "    time.sleep(runtime)\n",
    "    stop_recording = True\n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    print(\"Recording and transcription stopped.\")\n",
    "except KeyboardInterrupt:\n",
    "    stop_recording = True\n",
    "    print(\"Stopped by user.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b800d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started...\n",
      "Transcription started...\n",
      "Recording and transcription are running. Press Ctrl+C to stop.\n",
      "[2025-07-19 01:46:34] Okay, so here is a test using transcription that is non-threaded. Let's see how it will work. Let's try it out.\n",
      "[2025-07-19 01:46:45] for a very long time like that, will it pick it up? Will it crash? What will happen? If I... wait half a second and do that, will it...\n",
      "[2025-07-19 01:46:55] record what I'm saying or just skip over it, because I think it will skip over it.\n",
      "[2025-07-19 01:47:06] crazy is it picking it up if it's picking it up that's very impressive i don't know huh if i could\n",
      "[2025-07-19 01:47:16] 1 2 3 4 5 6 7 8 9 10 11 12 13 14\n",
      "[2025-07-19 01:47:27] 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 52, 53, 54, 54, 55, 56, 57, 58, 59, 60, 61, 60, 61, 62, 63, 62, 63, 62, 63, 63, 64, 63, 64, 63,\n",
      "[2025-07-19 01:47:37] 27 28 29 30\n",
      "[2025-07-19 01:47:48] Okay, so it got all of that apparently. I got up to 30 and um, might have crashed.\n",
      "[2025-07-19 01:47:58] I think it probably crashed um seems to be saving to a file fine\n",
      "[2025-07-19 01:48:09] Seems the recording conversation is fine until it stops.\n",
      "[2025-07-19 01:48:19] Oh got to 14 is it just really slow on the process\n",
      "[2025-07-19 01:48:29] or\n",
      "[2025-07-19 01:48:40] Oh cu\n",
      "[2025-07-19 01:48:50] Let's see if it picks up all of it. Okay, so it got to 30. It got to 30 just fine.\n",
      "[2025-07-19 01:49:01] Okay, okay, so it's a little bit slow, but it is recording everything.\n",
      "[2025-07-19 01:49:11] It doesn't seem to have skipped over any of the numbers. It might have duplicated them, but that's not that big of an issue.\n",
      "[2025-07-19 01:49:22] Yeah, okay, so I think it seems to be working pretty well. It's just a little bit slow at times, which is not that big of an issue.\n",
      "[2025-07-19 01:49:32] I think it's fine it's just gonna have to like think it's made to make appointments and remind me of stuff which isn't\n",
      "[2025-07-19 01:49:43] Time sensitive that makes any sense because like they're in conversation We could be talking and then afterwards it will\n",
      "[2025-07-19 01:49:53] and make an appointment for like on calendar and most likely the appointment isn't gonna be five minutes from now so if it's a little behind that's fine\n",
      "[2025-07-19 01:50:04] Okay, so I'd say this is a success. We found our running model.\n",
      "[2025-07-19 01:50:14] As a new python file. God my chair is so loud. Alright.\n",
      "[2025-07-19 01:50:25] Okay so we got our audio transcriber that P...\n",
      "[2025-07-19 01:50:35] Function testing. Alright cool. Let me uh, control C. To stop it. How do I stop it?\n",
      "Stopping...\n",
      "Recording stopped.\n",
      "[2025-07-19 01:50:46] tightly\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import queue\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import whisper\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"medium\")\n",
    "\n",
    "samplerate = 16000  # 16kHz sample rate\n",
    "chunk_duration = 10  # seconds per chunk\n",
    "audio_queue = queue.Queue()\n",
    "stop_event = threading.Event()\n",
    "output_file = \"transcription-non-thread.txt\"\n",
    "\n",
    "def record_audio():\n",
    "    \"\"\"Continuously record audio and push raw audio data with timestamps to the queue.\"\"\"\n",
    "    print(\"Recording started...\")\n",
    "    while not stop_event.is_set():\n",
    "        recording = sd.rec(int(chunk_duration * samplerate), samplerate=samplerate, channels=1, dtype='float32')\n",
    "        sd.wait()\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        audio_queue.put((recording.copy(), timestamp))\n",
    "    print(\"Recording stopped.\")\n",
    "\n",
    "def transcribe_audio():\n",
    "    \"\"\"Continuously transcribe audio from the queue and save transcriptions with timestamps.\"\"\"\n",
    "    print(\"Transcription started...\")\n",
    "    while not stop_event.is_set() or not audio_queue.empty():\n",
    "        try:\n",
    "            audio_data, timestamp = audio_queue.get(timeout=1)\n",
    "\n",
    "            # Whisper expects a 1D numpy array\n",
    "            audio_data = np.squeeze(audio_data)\n",
    "            result = model.transcribe(audio_data, fp16=False)\n",
    "\n",
    "            transcription = result['text'].strip()\n",
    "            if transcription:\n",
    "                log_entry = f\"[{timestamp}] {transcription}\\n\"\n",
    "                print(log_entry.strip())\n",
    "                with open(output_file, 'a') as f:\n",
    "                    f.write(log_entry)\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "    print(\"Transcription stopped.\")\n",
    "\n",
    "def main():\n",
    "    recorder_thread = threading.Thread(target=record_audio)\n",
    "    transcriber_thread = threading.Thread(target=transcribe_audio)\n",
    "\n",
    "    recorder_thread.start()\n",
    "    transcriber_thread.start()\n",
    "\n",
    "    print(\"Recording and transcription are running. Press Ctrl+C to stop.\")\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(0.5)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping...\")\n",
    "        stop_event.set()\n",
    "        recorder_thread.join()\n",
    "        transcriber_thread.join()\n",
    "        print(\"All processes stopped.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c40b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0: [2025-07-19 01:55:47] Okay, so I'm gonna make some quick data stuff. I'm gonna say like, oh I'm inviting you to my birthday party\n",
      "Line 1: [2025-07-19 01:55:58] at 6pm at Newark mall there's gonna be you know people there I'm also thinking about having a meeting at 6pm\n",
      "Line 2: [2025-07-19 01:56:08] on Thursday the 27th. So make sure you're there for that one. Very important. I also feel like\n",
      "Line 3: [2025-07-19 01:56:19] should have a meeting to discuss your stocks at 6.15 p.m.\n",
      "Line 4: [2025-07-19 01:56:29] and also I think we should really have a talk about the event\n",
      "Line 5: [2025-07-19 01:56:40] to do on the 26th of April 2027 which will be launching our company called Jar...\n",
      "Line 6: [2025-07-19 01:56:50] com and i think that's good so uh... yeah\n",
      "Line 7: [2025-07-19 01:57:01] recording\n",
      "Line 8: [2025-07-19 01:57:11] It is a\n"
     ]
    }
   ],
   "source": [
    "#ok so now we need to make it look for key words and information\n",
    "#first we need to mark the text that has already been read.\n",
    "#  so i think we add a 1 before the date if its been read\n",
    "#requirements:\n",
    "# 1. Read the transcription file line by line.\n",
    "# 2. get context from across lines to fidn out when there will be meetings.\n",
    "# 3. figure out what needs to be done. google calender api, alarm, notification, etc.\n",
    "\n",
    "line = 0\n",
    "\n",
    "def cointains_keywords(text,keywords):\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def mark_as_read(line):\n",
    "    # Mark the line as read by adding a '1' at the start\n",
    "    return \"1\" + line[1:]\n",
    "\n",
    "with open('Transcription.txt', 'r') as file:\n",
    "    for line_index, line_content in enumerate(file):\n",
    "        line = line_index\n",
    "        print(f\"Line {line_index}: {line_content.strip()}\")\n",
    "\n",
    "#ok so there are like a million ways to do this. i think i need to ahve a database of \n",
    "# keywords and then check if the line contains any of those keywords.\n",
    "# if it does, i will identify which one (or ones) it contains\n",
    "# then i will go through one by one and gather the context around it for each keyword. \n",
    "# then i will give the context to a gpt model to get the key information out of it\n",
    "# once i have the key information like the time, date, and what it is for, i will add it \n",
    "# to the google calendar, and move onto the next keyword. \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170e33d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
