{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8753a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 72.1M/72.1M [00:04<00:00, 16.2MiB/s]\n",
      "C:\\Users\\vitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test test test I'm gonna be talking like this let's see how it handles when it's super loud and then also when I'm really close and it's super loud or when I'm pretty far away and it's kind of quiet let's see if it can handle a little bit of this a little bit of that some flaps and I think birthday party power off run function meeting at 5 p.m. in new Plaza Square you need a doctor's appointment pretty soon make sure you get that going don't forget to visit the birthday party at 7 p.m.\n"
     ]
    }
   ],
   "source": [
    "#first it decodes the message and writes it as a text file:\n",
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"tiny\")  # Options: tiny, base, small, medium, large\n",
    "\n",
    "result = model.transcribe(\"command_test.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661e7e9",
   "metadata": {},
   "source": [
    "first lets see if it can do this in real time. \n",
    "to do this, since the model is trained on 30 second intervals we will need to break the audio up into 30 second chunks.\n",
    "then while its transcribing one section, it will be recording the next section, that way its going to be at most 30 seconds behind.\n",
    "it will save these 30 second chunks to a file, labeled with date and time and then it will search through the file for any new information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorder: Recording audio...\n",
      "Main: Running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Exception in thread Thread-4 (processing_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1520.0_x64__qbz5n2kfra8p0\\Lib\\threading.py\"\u001b[0m, line \u001b[35m1043\u001b[0m, in \u001b[35m_bootstrap_inner\u001b[0m\n",
      "    \u001b[31mself.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\vitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ipykernel\\ipkernel.py\"\u001b[0m, line \u001b[35m766\u001b[0m, in \u001b[35mrun_closure\u001b[0m\n",
      "    \u001b[31m_threading_Thread_run\u001b[0m\u001b[1;31m(self)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1520.0_x64__qbz5n2kfra8p0\\Lib\\threading.py\"\u001b[0m, line \u001b[35m994\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mself._target\u001b[0m\u001b[1;31m(*self._args, **self._kwargs)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\vitya\\AppData\\Local\\Temp\\ipykernel_46116\\3650845021.py\"\u001b[0m, line \u001b[35m68\u001b[0m, in \u001b[35mprocessing_thread\u001b[0m\n",
      "    \u001b[31mtranscribe_audio\u001b[0m\u001b[1;31m(audio_data)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\vitya\\AppData\\Local\\Temp\\ipykernel_46116\\3650845021.py\"\u001b[0m, line \u001b[35m55\u001b[0m, in \u001b[35mtranscribe_audio\u001b[0m\n",
      "    result = model.transcribe(buffer_mp3)\n",
      "  File \u001b[35m\"C:\\Users\\vitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\whisper\\transcribe.py\"\u001b[0m, line \u001b[35m139\u001b[0m, in \u001b[35mtranscribe\u001b[0m\n",
      "    mel = log_mel_spectrogram(audio, model.dims.n_mels, padding=N_SAMPLES)\n",
      "  File \u001b[35m\"C:\\Users\\vitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\whisper\\audio.py\"\u001b[0m, line \u001b[35m141\u001b[0m, in \u001b[35mlog_mel_spectrogram\u001b[0m\n",
      "    audio = torch.from_numpy(audio)\n",
      "\u001b[1;35mTypeError\u001b[0m: \u001b[35mexpected np.ndarray (got _io.BytesIO)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorder: Finished recording.\n",
      "Recorder: Audio added to queue.\n",
      "Recorder: Recording audio...\n",
      "Transcriber: Transcribing audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Audio added to queue.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Audio added to queue.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Audio added to queue.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Audio added to queue.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Audio added to queue.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Queue is full, skipping this recording.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Queue is full, skipping this recording.\n",
      "Recorder: Recording audio...\n",
      "Recorder: Finished recording.\n",
      "Recorder: Queue is full, skipping this recording.\n",
      "Recorder: Recording audio...\n",
      "Main: Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import os\n",
    "import numpy as np\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "from pydub import AudioSegment\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "file_lock = threading.Lock()\n",
    "\n",
    "duration = 30  # seconds\n",
    "samplerate = 16000\n",
    "stop_recording = False\n",
    "\n",
    "recording_buffer = {\n",
    "    \"Thread-1\": None,\n",
    "    \"Thread-2\": None\n",
    "}\n",
    "\n",
    "def record_audio(thread_name):\n",
    "    print(f\"{thread_name}: Recording for {duration}s...\")\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    return recording\n",
    "\n",
    "def save_and_transcribe(thread_name, audio_data):\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S-%f\")\n",
    "    wav_filename = f\"{thread_name}_{current_datetime}.wav\"\n",
    "    mp3_filename = f\"{thread_name}_{current_datetime}.mp3\"\n",
    "\n",
    "    write(wav_filename, samplerate, audio_data)\n",
    "    audio = AudioSegment.from_wav(wav_filename)\n",
    "    audio.export(mp3_filename, format=\"mp3\")\n",
    "    os.remove(wav_filename)\n",
    "\n",
    "    print(f\"{thread_name}: Transcribing...\")\n",
    "    result = model.transcribe(mp3_filename)\n",
    "    clean_text = result[\"text\"].replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "\n",
    "    with file_lock:\n",
    "        with open(\"transcription.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"[{datetime.now()}][{thread_name}] {clean_text}\\n\")\n",
    "\n",
    "    os.remove(mp3_filename)\n",
    "    print(f\"{thread_name}: Transcription complete and file cleaned up.\")\n",
    "\n",
    "def worker(my_name, partner_name):\n",
    "    global stop_recording\n",
    "    while not stop_recording:\n",
    "        # Record audio\n",
    "        audio_data = record_audio(my_name)\n",
    "        # Store for the partner to process later (if needed)\n",
    "        recording_buffer[my_name] = audio_data\n",
    "\n",
    "        # Allow partner to record while this thread processes previous data\n",
    "        if recording_buffer[partner_name] is not None:\n",
    "            save_and_transcribe(partner_name, recording_buffer[partner_name])\n",
    "            recording_buffer[partner_name] = None\n",
    "        else:\n",
    "            # If partner hasn't recorded yet, process own data\n",
    "            save_and_transcribe(my_name, audio_data)\n",
    "            recording_buffer[my_name] = None\n",
    "\n",
    "def start_alternating_threads():\n",
    "    thread1 = threading.Thread(target=worker, args=(\"Thread-1\", \"Thread-2\"))\n",
    "    thread2 = threading.Thread(target=worker, args=(\"Thread-2\", \"Thread-1\"))\n",
    "\n",
    "    thread1.start()\n",
    "    # Stagger the second thread to alternate\n",
    "    time.sleep(duration)\n",
    "    thread2.start()\n",
    "\n",
    "    return thread1, thread2\n",
    "\n",
    "try:\n",
    "    thread1, thread2 = start_alternating_threads()\n",
    "    runtime = 5 * 60  # Run for 5 minutes, adjust as needed\n",
    "    time.sleep(runtime)\n",
    "    stop_recording = True\n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    print(\"Recording and transcription stopped.\")\n",
    "except KeyboardInterrupt:\n",
    "    stop_recording = True\n",
    "    print(\"Stopped by user.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5484b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code words and new information\n",
    "# first it will look throught the transcript for any new information.\n",
    "# it will do this any time that there is a break in the transcription.\n",
    "# every 5 minutes it will check through the transcript to see if there is a break with no new text\n",
    "# if there isnt, then it will look through from the last time it checked, up to the current time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2983c779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n",
      "Thread-1: Transcription complete and file cleaned up.\n",
      "Thread-1: Recording for 30s...\n",
      "Thread-2: Transcribing...\n",
      "Thread-2: Transcription complete and file cleaned up.\n",
      "Thread-2: Recording for 30s...\n",
      "Thread-1: Transcribing...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import os\n",
    "import numpy as np\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "from pydub import AudioSegment\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "file_lock = threading.Lock()\n",
    "\n",
    "duration = 30  # seconds\n",
    "samplerate = 16000\n",
    "stop_recording = False\n",
    "\n",
    "recording_buffer = {\n",
    "    \"Thread-1\": None,\n",
    "    \"Thread-2\": None\n",
    "}\n",
    "\n",
    "def record_audio(thread_name):\n",
    "    print(f\"{thread_name}: Recording for {duration}s...\")\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    return recording\n",
    "\n",
    "def save_and_transcribe(thread_name, audio_data):\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S-%f\")\n",
    "    wav_filename = f\"{thread_name}_{current_datetime}.wav\"\n",
    "    mp3_filename = f\"{thread_name}_{current_datetime}.mp3\"\n",
    "\n",
    "    write(wav_filename, samplerate, audio_data)\n",
    "    audio = AudioSegment.from_wav(wav_filename)\n",
    "    audio.export(mp3_filename, format=\"mp3\")\n",
    "    os.remove(wav_filename)\n",
    "\n",
    "    print(f\"{thread_name}: Transcribing...\")\n",
    "    result = model.transcribe(mp3_filename)\n",
    "    clean_text = result[\"text\"].replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "\n",
    "    with file_lock:\n",
    "        with open(\"transcription.txt\", \"a\") as f:\n",
    "            f.write(f\"[{datetime.now()}][{thread_name}] {clean_text}\\n\")\n",
    "\n",
    "    os.remove(mp3_filename)\n",
    "    print(f\"{thread_name}: Transcription complete and file cleaned up.\")\n",
    "\n",
    "def worker(my_name, partner_name):\n",
    "    global stop_recording\n",
    "    while not stop_recording:\n",
    "        # Record audio\n",
    "        audio_data = record_audio(my_name)\n",
    "        # Store for the partner to process later (if needed)\n",
    "        recording_buffer[my_name] = audio_data\n",
    "\n",
    "        # Allow partner to record while this thread processes previous data\n",
    "        if recording_buffer[partner_name] is not None:\n",
    "            save_and_transcribe(partner_name, recording_buffer[partner_name])\n",
    "            recording_buffer[partner_name] = None\n",
    "        else:\n",
    "            # If partner hasn't recorded yet, process own data\n",
    "            save_and_transcribe(my_name, audio_data)\n",
    "            recording_buffer[my_name] = None\n",
    "\n",
    "def start_alternating_threads():\n",
    "    thread1 = threading.Thread(target=worker, args=(\"Thread-1\", \"Thread-2\"))\n",
    "    thread2 = threading.Thread(target=worker, args=(\"Thread-2\", \"Thread-1\"))\n",
    "\n",
    "    thread1.start()\n",
    "    # Stagger the second thread to alternate\n",
    "    time.sleep(duration)\n",
    "    thread2.start()\n",
    "\n",
    "    return thread1, thread2\n",
    "\n",
    "try:\n",
    "    thread1, thread2 = start_alternating_threads()\n",
    "    runtime = 5 * 60  # Run for 5 minutes, adjust as needed\n",
    "    time.sleep(runtime)\n",
    "    stop_recording = True\n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    print(\"Recording and transcription stopped.\")\n",
    "except KeyboardInterrupt:\n",
    "    stop_recording = True\n",
    "    print(\"Stopped by user.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b800d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c40b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
